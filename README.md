### otus_qa_web_course

## Описание работы скрипта:

С помощь модуля argparse при запуске возможно задать путь до лог файла или до дирректории сордержащие лог файлы. Для
этого используется ключ `-f`. Привет использования
`Python .\log_parser.py -f=D:\\repository\\otus_qa_web_course`

В процедуре parse_dir(args) осуществляется поиск *.log файлов. Процедура на вход принимает переданный путь через
агргумент. Далее в цикле (Если найденно несколько лог файлов), проводиться парсинг логов. с записью результата в json
файл. Наименование результирующего файла соответствует полному имени файла логов с расширением.

- Для каждого запроса из лога производиться сбор иследующей информации:
    - Метод запроса: POST|GET|PUT|DELETE|HEAD|OPTIONS
    - URL с которого осуществляется запрос (допустимо пустое значение - подменяется на None)
    - IP адресс с которого был запрос
    - длительность запроса : "DURATION"
    - Дата и время запроса.

Вся необходимая информация собирается за 1 проход по лог файлу. Для выбора топ-3 колличества и длительности запросов,
используется сортировка среди собранных значений. функция sorted. В качестве значения для сортировки, передается
соответствующее значение из словаря dict_ip_requests и списка list_ip_duration.

Полученные данные записываются в json файл с помощью функции write_json_file. Данная функция вызывается внутри функции
parse_log_file для каждого нового файла.

# Цель:

Потренироваться писать парсеры для логов.

Написать скрипт анализа приложенного access.log файла

Ссылка на файл access.log приложена в материалах к занятию

## Формат записи в файле лога:

%h %t "%r" %>s %b "%{Referer}i" "%{User-Agent}i" %D

- `%h` - имя удаленного хоста
- `%t`  - время получения запроса
- `%r`  - тип запроса, его содержимое и версия
- `%s` - код состояния HTTP
- `%b` - количество отданных сервером байт
- `%{Referer}` - URL-источник запроса
- `%{User-Agent}` - HTTP-заголовок, содержащий информацию о запросе
- `%D` - длительность запроса в миллисекундах

## Требования к реализации

1. Должна быть возможность указать директорий где искать логи или конкретный файл
2. Должна быть возможность обработки всех логов внутри одного директория (статистика по каждому логу должна выводиться
   отдельно и должна быть сохранена в отдельном json-файле)
3. Для access.log должна собираться следующая информация:
    1. общее количество выполненных запросов
    2. количество запросов по HTTP-методам: GET - 20, POST - 10 и т.п. (список необходимых методов можно посмотреть в
       RFC: https://datatracker.ietf.org/doc/html/rfc7231#section-4
       и https://datatracker.ietf.org/doc/html/rfc5789#section-2)
    3. топ 3 IP адресов, с которых были сделаны запросы
    4. топ 3 самых долгих запросов, должно быть видно метод, URL-источник запроса, IP, длительность, дату и время
       запроса

4. Собранная статистика должна быть сохранена в json файл и выведена в терминал в свободном (но понятном!) формате
5. Должен быть README.md файл, который описывает как работает скрипт

Критерии оценки:

1. Задание выполнено и сдаётся в формате pull-request
2. Соблюдается минимальный код-стайл
3. В pull-request не попали никакие лишние изменения, которые не связаны с заданием
4. Приложен скриншот с примером работы скрипта